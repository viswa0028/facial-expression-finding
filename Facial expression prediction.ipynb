{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary things required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import pathlib\n",
    "import cv2 \n",
    "import PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = pathlib.Path(\"images\\see\") # saving the path that contains the details of the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\\see\n"
     ]
    }
   ],
   "source": [
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assigning different images in different path to different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    'angry' : list(dir_path.glob('angry/*')),\n",
    "    'disgust' : list(dir_path.glob('disgust/*')),\n",
    "    'fear' : list(dir_path.glob('fear/*')),\n",
    "    'happy' : list(dir_path.glob('happy/*')),\n",
    "    'neutral' : list(dir_path.glob('neutral/*')),\n",
    "    'sad' : list(dir_path.glob('sad/*')),\n",
    "    'surprise' : list(dir_path.glob('surprise/*'))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labelling the different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_label = {\n",
    "    'angry':1,\n",
    "    'disgust':2,\n",
    "    'fear':3,\n",
    "    'happy':4,\n",
    "    'neutral':5,\n",
    "    'sad':6,\n",
    "    'surprise':7,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing each image and then appending to the respective variables for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = [],[]\n",
    "for train,images in train_data.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resize = cv2.resize(img,(180,180))\n",
    "        X.append(resize)\n",
    "        y.append(train_data_label[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) #Converting into a numpy array.\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the preprocessing for the y data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classification = len(train_data_label)\n",
    "Cnn = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape = (180,180,3)), #building the first layer\n",
    "    keras.layers.MaxPooling2D((2,2)), #maxpooling \n",
    "    keras.layers.Conv2D(filters=18,kernel_size=(3,3),activation='relu'), #similarly another layer\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Flatten(), #flattening the output\n",
    "    keras.layers.Dense(num_classification,activation='sigmoid') #final layer to produce the output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnn.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 276ms/step - accuracy: 0.2241 - loss: 18.1433\n",
      "Epoch 2/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 277ms/step - accuracy: 0.2797 - loss: 1.7808\n",
      "Epoch 3/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 388ms/step - accuracy: 0.3280 - loss: 1.6755\n",
      "Epoch 4/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 412ms/step - accuracy: 0.3817 - loss: 1.5448\n",
      "Epoch 5/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 336ms/step - accuracy: 0.4288 - loss: 1.4384\n",
      "Epoch 6/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 356ms/step - accuracy: 0.4717 - loss: 1.3463\n",
      "Epoch 7/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 412ms/step - accuracy: 0.4990 - loss: 1.2721\n",
      "Epoch 8/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 411ms/step - accuracy: 0.5296 - loss: 1.2050\n",
      "Epoch 9/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 310ms/step - accuracy: 0.5626 - loss: 1.1231\n",
      "Epoch 10/10\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 289ms/step - accuracy: 0.5873 - loss: 1.0702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2dac31b25d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cnn.fit(X,y,epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is about 58% accurate which is great and also we can do the testing with different images and also build different models with different variables for different answers and higher accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pathlib.Path(\"images\\happy_test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv2.imread(str(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv2.resize(X_test,(180,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 180, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to increase a dimension of the X_test (Compare with the dimension of X,X_test previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test after reshaping: (1, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "# Add batch dimension to X_test\n",
    "X_test = np.expand_dims(X_test, axis=0)\n",
    "print(f\"Shape of X_test after reshaping: {X_test.shape}\")\n",
    "# Output should be: (1, 180, 180, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = Cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12321675 0.02505752 0.14346993 0.26546773 0.1759672  0.18390028\n",
      "  0.08292065]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So I gave a input as happy and the prediction for the happy was the highest so I think the model is working is greatly.
       The dataset can be found at :- https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
